# HybridLLMGateway

HybridLLMGateway 是一款专为中小型技术团队设计的开源大模型调用网关。它不仅提供多供应商接入、权限控制与限流，更核心的功能在于其离在线混部调度机制，旨在极小化算力闲置，最大化提升整体吞吐量。

## 🚀 核心价值：削峰填谷

中小型团队通常面临两难：

为高峰买单：为了保证 C 端用户实时体验，预留大量算力，导致低谷期资源浪费。

任务积压：大量的离线数据处理（如知识库向量化、报表分析）无法利用碎片时间高效完成。

**Fluxion 通过优先级抢占算法解决此问题：**

C 端请求（实时型）：拥有最高优先级，随到随走，立即抢占算力。

任务请求（离线型）：自动填充算力空隙。当系统检测到实时请求减少时，自动加速处理积压任务；当实时请求涌入时，自动挂起或限缩任务并发。

## ✨ 主要功能

🔌 多模型适配：一键接入 OpenAI, Claude, 智谱 AI, 通义千问, Llama (Ollama/vLLM) 等。

⚖️ 动态调度引擎：基于响应延迟（Latency）和并发度（Concurrency）的实时反馈机制，动态调整离线任务权重。

⚡ 优先级抢占：内置双层队列，确保实时请求在毫秒级内获得算力响应，不受离线大批量任务阻塞。

### 🛡️ 企业级控制：

多租户管理：不同项目组配置独立的 API Key 和配额。

精细限流：支持 RPM (每分钟请求数) 和 TPM (每分钟 Token 数) 限制。

成本审计：记录详细的调用日志，统计各部门消耗成本。

### 📦 轻量化部署：纯 Python 开发，支持 Docker 一键部署，对环境依赖极低。

## 🏗️ 架构概览
Plaintext

[ 客户端/应用层 ]
      |
      ▼
[ Fluxion Gateway ]
  /        \
 [实时队列] [任务队列]  <-- 动态调度器 (Dynamic Scheduler)
  \        /
      ▼
[ 模型服务商 (API/本地推理) ]

## 🛠️ 快速开始

1. 环境准备
Bash

python 3.10+
redis 6.0+ (用于状态同步与队列管理)
2. 安装与运行
Bash

git clone https://github.com/yourname/fluxion.git
cd fluxion
pip install -r requirements.txt

配置你的模型 API Key

cp config.example.yaml config.yaml

启动服务

python main.py

📈 性能预期
在典型测试环境下，Fluxion 相比于传统的静态限流网关，在处理同等规模的离线任务时，硬件资源利用率可提升 40% - 60%，同时保证 C 端请求的 P99 延迟波动小于 5%。
